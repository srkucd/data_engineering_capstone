{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 0: Preparation and import data from s3\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (1.14.20)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.20 in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from boto3) (1.17.20)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from boto3) (0.3.3)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.20->boto3) (1.22)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.20->boto3) (0.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.20->boto3) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.20->boto3) (1.11.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.2.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: s3fs in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (0.4.2)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from s3fs) (0.7.4)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from s3fs) (1.17.20)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (1.22)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (0.10.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (0.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.12.91->s3fs) (1.11.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.2.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pyspark in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (3.0.0)\n",
      "Requirement already satisfied: py4j==0.10.9 in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from pyspark) (0.10.9)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.2.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: cqlsh in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (5.0.4)\n",
      "Requirement already satisfied: cassandra-driver in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from cqlsh) (3.24.0)\n",
      "Requirement already satisfied: cql in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from cqlsh) (1.4.0)\n",
      "Requirement already satisfied: six>=1.9 in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from cassandra-driver->cqlsh) (1.11.0)\n",
      "Requirement already satisfied: geomet<0.3,>=0.1 in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from cassandra-driver->cqlsh) (0.2.1.post1)\n",
      "Requirement already satisfied: thrift in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from cql->cqlsh) (0.13.0)\n",
      "Requirement already satisfied: click in /Users/ishirunkang/anaconda3/lib/python3.6/site-packages (from geomet<0.3,>=0.1->cassandra-driver->cqlsh) (6.7)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.2.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Before we continue, we need to install related python package.\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install boto3\n",
    "!{sys.executable} -m pip install s3fs\n",
    "!{sys.executable} -m pip install pyspark\n",
    "!{sys.executable} -m pip install cqlsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import os\n",
    "import boto3\n",
    "import uuid\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('iam.cfg')\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS_CREDS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS_CREDS']['AWS_SECRET_ACCESS_KEY']\n",
    "\n",
    "client=boto3.client('s3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scope the Project and Gather Data\n",
    "\n",
    "#### Project description:\n",
    "\n",
    "This project will be separate to multiple parts, and all four dataset will be used. \n",
    "\n",
    "Before we talk about the details, we need to know the characteristics of relational DB and non-relational DB.\n",
    "\n",
    "For relational DB, its characteristics is low redundancy and high completeness, which means it is very suitable for small or medium size data, and the database does not change so much. In our case, we should store temperature, airport code and US cities demographic data into a relational database that meets 3NF because it does not always change so much and the volume of data is not that large.\n",
    "\n",
    "For non-relational DB, its characteristics is higher elasticity, faster read & write speed and evoving data volume. In our case, we should save I94 data into non-relational DB. Because this piece of data need to make ETL process almost every minutes in real world background, and it need dynamic write and read for real-time data monitoring.\n",
    "\n",
    "\n",
    "The final solution will work as a a database management system. When user input the time or time period and the column they interested in (e.g., visa type), the system will return related data as a dataframe. For example, a user needs to know where are the busiest airport for investment visa holder(E-1 visa) in 2016 and its basic information such as temperature, and the status of the city such as population(age, majority race, etc.), or when is the peak-time for international student come to the United States and where are they come from.\n",
    "\n",
    "* Data will be imported from Amazon S3\n",
    "* Relational DB will be implement on AWS Redshift\n",
    "* Non-Relationalship DB will be implement on Amazon Keyspace, and data backup will be stored at S3 as parquet format.\n",
    "* Data cleaning and ETL process will be implement on Amazon EMR with Spark\n",
    "\n",
    "#### The dataset is going to use in this project are:\n",
    "\n",
    "* I94 Immigration Data: This data comes from the US National Tourism and Trade Office. A data dictionary is included in the workspace. https://travel.trade.gov/research/reports/i94/historical/2016.html is where the data comes from. There's a sample file so you can take a look at the data in csv format before reading it all in. You do not have to use the entire dataset, just use what you need to accomplish the goal you set at the beginning of the project.\n",
    "* World Temperature Data: This dataset came from Kaggle. You can read more about it here: https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data.\n",
    "* U.S. City Demographic Data: This data comes from OpenSoft. You can read more about it here: https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/.\n",
    "* Airport Code Table: This is a simple table of airport codes and corresponding cities. It comes from here:https://datahub.io/core/airport-codes#data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\t\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "\n",
    "while True:\n",
    "    if os.path.isdir('16_jan.parquet'):\n",
    "        break\n",
    "    else:\n",
    "        sql = '''SELECT id_, cicid, i94yr, i94mon, i94cit, i94res, i94port,\n",
    "                 arrdate, i94mode, i94addr, depdate, i94bir, i94visa,\n",
    "                 count, dtadfile, visapost, occup, entdepa, entdepd,\n",
    "                 entdepu, matflag, biryear, dtaddto, gender, insnum,\n",
    "                 airline, admnum, fltno, visatype FROM i94'''\n",
    "        \n",
    "        i94_url='s3://srk-data-eng-capstone/i94/i94_jan16_sub.sas7bdat'\n",
    "        i94 = pd.read_sas(i94_url, 'sas7bdat',encoding=\"ISO-8859-1\").drop_duplicates()\n",
    "        i94['id_'] = pd.Series([uuid.uuid1() for each in range(len(i94))])\n",
    "        i94['dtadfile'].fillna(-1,inplace=True)\n",
    "        for each in i94:\n",
    "            dt=i94[each].dtype\n",
    "            if dt == 'object':\n",
    "                i94[each].fillna('Null',inplace=True)\n",
    "            else:\n",
    "                i94[each].fillna(-1,inplace=True)\n",
    "        i94.to_csv('16_jan.csv', index=False)\n",
    "        df_spark=spark.read.option('header','true').csv('16_jan.csv')\n",
    "        df_spark.createOrReplaceTempView('i94')\n",
    "        parquet_data=spark.sql(sql)\n",
    "        parquet_data.write.parquet('16_jan.parquet',mode='overwrite')\n",
    "        os.system('aws s3 cp 16_jan.parquet s3://i94-backup --recursive')\n",
    "        break        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "from ssl import SSLContext, PROTOCOL_TLSv1, CERT_REQUIRED\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "from cassandra import ConsistencyLevel\n",
    "from tqdm import tqdm\n",
    "\n",
    "ssl_context = SSLContext(PROTOCOL_TLSv1)\n",
    "ssl_context.load_verify_locations('AmazonRootCA1.pem')\n",
    "ssl_context.verify_mode = CERT_REQUIRED\n",
    "auth_provider = PlainTextAuthProvider(username=str(config['APACHE_CASSANDRA_CREDS']['CASSANDRA_USERNAME']), password=str(config['APACHE_CASSANDRA_CREDS']['CASSANDRA_PASSWORD']))\n",
    "cluster = Cluster(['cassandra.eu-west-1.amazonaws.com'], ssl_context=ssl_context, auth_provider=auth_provider, port=9142)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient...\n",
      "Table well-prepared. you can input data from dataset.\n"
     ]
    }
   ],
   "source": [
    "print('Patient...')\n",
    "session = cluster.connect()\n",
    "create_keyspace=\"\"\"CREATE KEYSPACE IF NOT EXISTS \"i94\"\n",
    "                   WITH REPLICATION={'class':'SingleRegionStrategy'}\"\"\"\n",
    "session.execute(create_keyspace)\n",
    "sleep(10)\n",
    "\n",
    "create_table=\"\"\"CREATE TABLE IF NOT EXISTS \"i94\".i94 (\n",
    "                                                      cicid DOUBLE,\n",
    "                                                      i94yr DOUBLE,\n",
    "                                                      i94mon DOUBLE,\n",
    "                                                      i94cit DOUBLE,\n",
    "                                                      i94res DOUBLE,\n",
    "                                                      i94port TEXT,\n",
    "                                                      arrdate DOUBLE,\n",
    "                                                      i94mode DOUBLE,\n",
    "                                                      i94addr TEXT,\n",
    "                                                      depdate DOUBLE,\n",
    "                                                      i94bir DOUBLE,\n",
    "                                                      i94visa DOUBLE,\n",
    "                                                      count DOUBLE,\n",
    "                                                      dtadfile DOUBLE,\n",
    "                                                      visapost TEXT,\n",
    "                                                      occup TEXT,\n",
    "                                                      entdepa TEXT,\n",
    "                                                      entdepd TEXT,\n",
    "                                                      entdepu TEXT,\n",
    "                                                      matflag TEXT,\n",
    "                                                      biryear DOUBLE,\n",
    "                                                      dtaddto TEXT,\n",
    "                                                      gender TEXT,\n",
    "                                                      insnum TEXT,\n",
    "                                                      airline TEXT,\n",
    "                                                      admnum DOUBLE,\n",
    "                                                      fltno TEXT,\n",
    "                                                      visatype TEXT,\n",
    "                                                      id_ TEXT,\n",
    "                                                      PRIMARY KEY(id_)\n",
    "                ) \"\"\"\n",
    "session.execute(create_table)\n",
    "sleep(10)\n",
    "print('Table well-prepared. you can input data from dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62693it [59:14, 17.98it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c2c36da5d6d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m                       lists[20],lists[21],lists[22],lists[23],lists[24],lists[25],lists[26],lists[27],lists[28])\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0msql\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformated_sql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsistency_level\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConsistencyLevel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOCAL_QUORUM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/cassandra/cluster.cpython-36m-darwin.so\u001b[0m in \u001b[0;36mcassandra.cluster.Session.prepare\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/cassandra/cluster.cpython-36m-darwin.so\u001b[0m in \u001b[0;36mcassandra.cluster.Session.prepare_on_all_hosts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/cassandra/cluster.cpython-36m-darwin.so\u001b[0m in \u001b[0;36mcassandra.cluster.ResponseFuture.result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "62693it [59:31, 17.98it/s]"
     ]
    }
   ],
   "source": [
    "origin_sql=\"\"\"INSERT INTO \"i94\".i94 (\"cicid\",\"i94yr\",\"i94mon\",\"i94cit\",\"i94res\",\"i94port\",\"arrdate\",\"i94mode\",\"i94addr\",\"depdate\",\n",
    "                              \"i94bir\",\"i94visa\",\"count\",\"dtadfile\",\"visapost\",\"occup\",\"entdepa\",\"entdepd\",\"entdepu\",\"matflag\",\n",
    "                              \"biryear\",\"dtaddto\",\"gender\",\"insnum\",\"airline\",\"admnum\",\"fltno\",\"visatype\",\"id_\")\n",
    "                              VALUES ({0},{1},{2},{3},{4},'{5}',{6},{7},'{8}',{9},\n",
    "                                      {10},{11},{12},{13},'{14}','{15}','{16}','{17}','{18}','{19}',\n",
    "                                      {20},'{21}','{22}','{23}','{24}',{25},'{26}','{27}','{28}')\"\"\"\n",
    "\n",
    "\n",
    "total_length=len(pd.read_csv('16_jan.csv'))\n",
    "\n",
    "with open('{}.csv'.format('16_jan'),'r') as csv:\n",
    "    #Ignore the first line, which is column head.\n",
    "    csv=iter(csv)\n",
    "    next(csv)\n",
    "#     counts=0\n",
    "    for each in tqdm(csv):\n",
    "        lists=[]\n",
    "        columns=each.split(',')\n",
    "        cicid=columns[0]\n",
    "        i94yr=columns[1]\n",
    "        i94mon=columns[2]\n",
    "        i94cit=columns[3]\n",
    "        i94res=columns[4]\n",
    "        i94port=columns[5]\n",
    "        arrdate=columns[6]\n",
    "        i94mode=columns[7]\n",
    "        i94addr=columns[8]\n",
    "        depdate=columns[9]\n",
    "        i94bir=columns[10]\n",
    "        i94visa=columns[11]\n",
    "        count=columns[12]\n",
    "        dtadfile=columns[13]\n",
    "        visapost=columns[14]\n",
    "        occup=columns[15]\n",
    "        entdepa=columns[16]\n",
    "        entdepd=columns[17]\n",
    "        entdepu=columns[18]\n",
    "        matflag=columns[19]\n",
    "        biryear=columns[20]\n",
    "        dtaddto=columns[21]\n",
    "        gender=columns[22]\n",
    "        insnum=columns[23]\n",
    "        airline=columns[24]\n",
    "        admnum=columns[25]\n",
    "        fltno=columns[26]\n",
    "        visatype=columns[27]\n",
    "        id_=columns[28]        \n",
    "        \n",
    "        original_list=[cicid,i94yr,i94mon,i94cit,i94res,i94port,arrdate,i94mode,i94addr,depdate,i94bir,i94visa,\n",
    "                      count,dtadfile,visapost,occup,entdepa,entdepd,entdepu,matflag,biryear,dtaddto,gender,insnum,\n",
    "                      airline,admnum,fltno,visatype,id_]\n",
    "        \n",
    "        for each in original_list:\n",
    "            try:\n",
    "                each = float(each)\n",
    "                lists.append(each)\n",
    "            except:\n",
    "                if each == '':\n",
    "                    each = None\n",
    "                    lists.append(each)\n",
    "                else:\n",
    "                    lists.append(each)\n",
    "                    continue                            \n",
    "        \n",
    "        formated_sql=origin_sql.format(lists[0],lists[1],lists[2],lists[3],lists[4],lists[5],lists[6],lists[7],lists[8],lists[9],\n",
    "                      lists[10],lists[11],lists[12],lists[13],lists[14],lists[15],lists[16],lists[17],lists[18],lists[19],\n",
    "                      lists[20],lists[21],lists[22],lists[23],lists[24],lists[25],lists[26],lists[27],lists[28])\n",
    "        \n",
    "        sql=session.prepare(formated_sql)\n",
    "        sql.consistency_level = ConsistencyLevel.LOCAL_QUORUM\n",
    "        try:\n",
    "            session.execute(sql)\n",
    "        except:\n",
    "            session = cluster.connect()\n",
    "            session.execute(sql)\n",
    "        \n",
    "#         print('Import row{} complete.'.format(counts) + '{} remaining.'.format(total_length-counts))\n",
    "#         counts+=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        os.remove('16_jan.csv')\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_land_temperature_url = 's3://srk-data-eng-capstone/GlobalLandTemperaturesByCity.csv'\n",
    "airport_codes_url = 's3://srk-data-eng-capstone/airport-codes_csv.csv'\n",
    "us_city_demographics_url = 's3://srk-data-eng-capstone/us-cities-demographics.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_land_temperature = pd.read_csv(global_land_temperature_url)\n",
    "airport_codes=pd.read_csv(airport_codes_url)\n",
    "us_city_demographics=pd.read_csv(us_city_demographics_url, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_cities = global_land_temperature['Country']=='United States'\n",
    "global_land_temperature = global_land_temperature[us_cities]\n",
    "global_land_temperature = global_land_temperature.drop(['Country'],axis=1)\n",
    "start_date = '2012-01-01'\n",
    "end_date = '2012-12-01'\n",
    "period = (global_land_temperature['dt']>=start_date) & (global_land_temperature['dt']<=end_date)\n",
    "global_land_temperature=global_land_temperature[period]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptable_airport = ['small_airport','medium_airport','large_airport']\n",
    "airport_codes = airport_codes[airport_codes['type'].isin(acceptable_airport)]\n",
    "#Do we need to delete rows with no IATA code?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>Stockton</td>\n",
       "      <td>California</td>\n",
       "      <td>32.5</td>\n",
       "      <td>150976.0</td>\n",
       "      <td>154674.0</td>\n",
       "      <td>305650</td>\n",
       "      <td>12822.0</td>\n",
       "      <td>79583.0</td>\n",
       "      <td>3.16</td>\n",
       "      <td>CA</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>19834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>Southfield</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>41.6</td>\n",
       "      <td>31369.0</td>\n",
       "      <td>41808.0</td>\n",
       "      <td>73177</td>\n",
       "      <td>4035.0</td>\n",
       "      <td>4011.0</td>\n",
       "      <td>2.27</td>\n",
       "      <td>MI</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>34.1</td>\n",
       "      <td>410615.0</td>\n",
       "      <td>437808.0</td>\n",
       "      <td>848423</td>\n",
       "      <td>42186.0</td>\n",
       "      <td>72456.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>IN</td>\n",
       "      <td>White</td>\n",
       "      <td>553665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>Somerville</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>31.0</td>\n",
       "      <td>41028.0</td>\n",
       "      <td>39306.0</td>\n",
       "      <td>80334</td>\n",
       "      <td>2103.0</td>\n",
       "      <td>22292.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>MA</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>Coral Springs</td>\n",
       "      <td>Florida</td>\n",
       "      <td>37.2</td>\n",
       "      <td>63316.0</td>\n",
       "      <td>66186.0</td>\n",
       "      <td>129502</td>\n",
       "      <td>4724.0</td>\n",
       "      <td>38552.0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>FL</td>\n",
       "      <td>White</td>\n",
       "      <td>90896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  City          State  Median Age  Male Population  \\\n",
       "0        Silver Spring       Maryland        33.8          40601.0   \n",
       "1               Quincy  Massachusetts        41.0          44129.0   \n",
       "2               Hoover        Alabama        38.5          38040.0   \n",
       "3     Rancho Cucamonga     California        34.5          88127.0   \n",
       "4               Newark     New Jersey        34.6         138040.0   \n",
       "...                ...            ...         ...              ...   \n",
       "2886          Stockton     California        32.5         150976.0   \n",
       "2887        Southfield       Michigan        41.6          31369.0   \n",
       "2888      Indianapolis        Indiana        34.1         410615.0   \n",
       "2889        Somerville  Massachusetts        31.0          41028.0   \n",
       "2890     Coral Springs        Florida        37.2          63316.0   \n",
       "\n",
       "      Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0               41862.0             82463              1562.0       30908.0   \n",
       "1               49500.0             93629              4147.0       32935.0   \n",
       "2               46799.0             84839              4819.0        8229.0   \n",
       "3               87105.0            175232              5821.0       33878.0   \n",
       "4              143873.0            281913              5829.0       86253.0   \n",
       "...                 ...               ...                 ...           ...   \n",
       "2886           154674.0            305650             12822.0       79583.0   \n",
       "2887            41808.0             73177              4035.0        4011.0   \n",
       "2888           437808.0            848423             42186.0       72456.0   \n",
       "2889            39306.0             80334              2103.0       22292.0   \n",
       "2890            66186.0            129502              4724.0       38552.0   \n",
       "\n",
       "      Average Household Size State Code                               Race  \\\n",
       "0                       2.60         MD                 Hispanic or Latino   \n",
       "1                       2.39         MA                              White   \n",
       "2                       2.58         AL                              Asian   \n",
       "3                       3.18         CA          Black or African-American   \n",
       "4                       2.73         NJ                              White   \n",
       "...                      ...        ...                                ...   \n",
       "2886                    3.16         CA  American Indian and Alaska Native   \n",
       "2887                    2.27         MI  American Indian and Alaska Native   \n",
       "2888                    2.53         IN                              White   \n",
       "2889                    2.43         MA  American Indian and Alaska Native   \n",
       "2890                    3.17         FL                              White   \n",
       "\n",
       "       Count  \n",
       "0      25924  \n",
       "1      58723  \n",
       "2       4759  \n",
       "3      24437  \n",
       "4      76402  \n",
       "...      ...  \n",
       "2886   19834  \n",
       "2887     983  \n",
       "2888  553665  \n",
       "2889     374  \n",
       "2890   90896  \n",
       "\n",
       "[2891 rows x 12 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_city_demographics\n",
    "#The relationship between this table and global temperature table: city=City\n",
    "#The relationship between this table and nosql table: State Code=i94addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00AS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Fulton Airport</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OK</td>\n",
       "      <td>Alex</td>\n",
       "      <td>00AS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AS</td>\n",
       "      <td>-97.8180194, 34.9428028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00AZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cordes Airport</td>\n",
       "      <td>3810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AZ</td>\n",
       "      <td>Cordes</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>-112.16500091552734, 34.305599212646484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55069</th>\n",
       "      <td>ZYYJ</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Yanji Chaoyangchuan Airport</td>\n",
       "      <td>624.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-22</td>\n",
       "      <td>Yanji</td>\n",
       "      <td>ZYYJ</td>\n",
       "      <td>YNJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.451004028, 42.8828010559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55070</th>\n",
       "      <td>ZYYK</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Yingkou Lanqi Airport</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Yingkou</td>\n",
       "      <td>ZYYK</td>\n",
       "      <td>YKH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.3586, 40.542524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55071</th>\n",
       "      <td>ZYYY</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Shenyang Dongta Airport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Shenyang</td>\n",
       "      <td>ZYYY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.49600219726562, 41.784400939941406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55073</th>\n",
       "      <td>ZZ-0002</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Glorioso Islands Airstrip</td>\n",
       "      <td>11.0</td>\n",
       "      <td>AF</td>\n",
       "      <td>TF</td>\n",
       "      <td>TF-U-A</td>\n",
       "      <td>Grande Glorieuse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.296388888900005, -11.584277777799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55074</th>\n",
       "      <td>ZZZZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Satsuma IÅjima Airport</td>\n",
       "      <td>338.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>JP</td>\n",
       "      <td>JP-46</td>\n",
       "      <td>Mishima-Mura</td>\n",
       "      <td>RJX7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.270556, 30.784722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39142 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ident            type                         name  elevation_ft  \\\n",
       "1         00AA   small_airport         Aero B Ranch Airport        3435.0   \n",
       "2         00AK   small_airport                 Lowell Field         450.0   \n",
       "3         00AL   small_airport                 Epps Airpark         820.0   \n",
       "5         00AS   small_airport               Fulton Airport        1100.0   \n",
       "6         00AZ   small_airport               Cordes Airport        3810.0   \n",
       "...        ...             ...                          ...           ...   \n",
       "55069     ZYYJ  medium_airport  Yanji Chaoyangchuan Airport         624.0   \n",
       "55070     ZYYK  medium_airport        Yingkou Lanqi Airport           0.0   \n",
       "55071     ZYYY  medium_airport      Shenyang Dongta Airport           NaN   \n",
       "55073  ZZ-0002   small_airport    Glorioso Islands Airstrip          11.0   \n",
       "55074     ZZZZ   small_airport      Satsuma IÅjima Airport         338.0   \n",
       "\n",
       "      continent iso_country iso_region      municipality gps_code iata_code  \\\n",
       "1           NaN          US      US-KS             Leoti     00AA       NaN   \n",
       "2           NaN          US      US-AK      Anchor Point     00AK       NaN   \n",
       "3           NaN          US      US-AL           Harvest     00AL       NaN   \n",
       "5           NaN          US      US-OK              Alex     00AS       NaN   \n",
       "6           NaN          US      US-AZ            Cordes     00AZ       NaN   \n",
       "...         ...         ...        ...               ...      ...       ...   \n",
       "55069        AS          CN      CN-22             Yanji     ZYYJ       YNJ   \n",
       "55070        AS          CN      CN-21           Yingkou     ZYYK       YKH   \n",
       "55071        AS          CN      CN-21          Shenyang     ZYYY       NaN   \n",
       "55073        AF          TF     TF-U-A  Grande Glorieuse      NaN       NaN   \n",
       "55074        AS          JP      JP-46      Mishima-Mura     RJX7       NaN   \n",
       "\n",
       "      local_code                              coordinates  \n",
       "1           00AA                   -101.473911, 38.704022  \n",
       "2           00AK              -151.695999146, 59.94919968  \n",
       "3           00AL    -86.77030181884766, 34.86479949951172  \n",
       "5           00AS                  -97.8180194, 34.9428028  \n",
       "6           00AZ  -112.16500091552734, 34.305599212646484  \n",
       "...          ...                                      ...  \n",
       "55069        NaN             129.451004028, 42.8828010559  \n",
       "55070        NaN                      122.3586, 40.542524  \n",
       "55071        NaN   123.49600219726562, 41.784400939941406  \n",
       "55073        NaN  47.296388888900005, -11.584277777799999  \n",
       "55074        NaN                    130.270556, 30.784722  \n",
       "\n",
       "[39142 rows x 12 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_codes\n",
    "#The relationship between nosql and this table: i94port=iata_code\n",
    "#The relationship between this table and global temperature table: city=municipality\n",
    "#The relationship between this table and US city demographics: iso_region[3:](if the United States)=State Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
